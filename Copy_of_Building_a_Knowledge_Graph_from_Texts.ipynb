{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbistline/model_test/blob/main/Copy_of_Building_a_Knowledge_Graph_from_Texts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Notebook of the course Pratical NLP with Python.\n",
        "\n",
        "Lesson: Project: Building a Knowledge Base from Texts\n",
        "\n",
        "Made by: [Fabio Chiusano](https://www.linkedin.com/in/fabio-chiusano-b6a3b311b/).\n",
        "\n",
        "Table of Contents:\n",
        "- Lesson Code\n",
        "  - Install and Import Libraries\n",
        "  - Load the Relation Extraction Model\n",
        "  - From Short Text to KB\n",
        "  - From Long Text to KB\n",
        "  - Filter and Normalize Entities with Wikipedia\n",
        "  - Extract KB from Web Article\n",
        "  - Google News: Extract KB from Multiple Articles\n",
        "  - Visualize KB\n",
        "- Code Exercises\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "94vMb9ybGqzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lesson Code"
      ],
      "metadata": {
        "id": "IaDP3vT7HIVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and Import Libraries"
      ],
      "metadata": {
        "id": "gOJp_QfYajVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L13CC9--ZbmA"
      },
      "outputs": [],
      "source": [
        "!pip install transformers wikipedia newspaper3k GoogleNews pyvis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# needed to load the REBEL model\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import math\n",
        "import torch\n",
        "\n",
        "# wrapper for wikipedia API\n",
        "import wikipedia\n",
        "\n",
        "# scraping of web articles\n",
        "from newspaper import Article, ArticleException\n",
        "\n",
        "# google news scraping\n",
        "from GoogleNews import GoogleNews\n",
        "\n",
        "# graph visualization\n",
        "from pyvis.network import Network\n",
        "\n",
        "# to show HTML in notebook\n",
        "import IPython"
      ],
      "metadata": {
        "id": "huw4xXHvZj9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Relation Extraction Model"
      ],
      "metadata": {
        "id": "kabfWxCTZnTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
      ],
      "metadata": {
        "id": "w-E86e2dZlmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Short Text to KB"
      ],
      "metadata": {
        "id": "WLR1NzylZsfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://huggingface.co/Babelscape/rebel-large\n",
        "def extract_relations_from_model_output(text):\n",
        "    relations = []\n",
        "    relation, subject, relation, object_ = '', '', '', ''\n",
        "    text = text.strip()\n",
        "    current = 'x'\n",
        "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
        "    for token in text_replaced.split():\n",
        "        if token == \"<triplet>\":\n",
        "            current = 't'\n",
        "            if relation != '':\n",
        "                relations.append({\n",
        "                    'head': subject.strip(),\n",
        "                    'type': relation.strip(),\n",
        "                    'tail': object_.strip()\n",
        "                })\n",
        "                relation = ''\n",
        "            subject = ''\n",
        "        elif token == \"<subj>\":\n",
        "            current = 's'\n",
        "            if relation != '':\n",
        "                relations.append({\n",
        "                    'head': subject.strip(),\n",
        "                    'type': relation.strip(),\n",
        "                    'tail': object_.strip()\n",
        "                })\n",
        "            object_ = ''\n",
        "        elif token == \"<obj>\":\n",
        "            current = 'o'\n",
        "            relation = ''\n",
        "        else:\n",
        "            if current == 't':\n",
        "                subject += ' ' + token\n",
        "            elif current == 's':\n",
        "                object_ += ' ' + token\n",
        "            elif current == 'o':\n",
        "                relation += ' ' + token\n",
        "    if subject != '' and relation != '' and object_ != '':\n",
        "        relations.append({\n",
        "            'head': subject.strip(),\n",
        "            'type': relation.strip(),\n",
        "            'tail': object_.strip()\n",
        "        })\n",
        "    return relations"
      ],
      "metadata": {
        "id": "1uf9Qaw4Zm6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# knowledge base class\n",
        "class KB():\n",
        "    def __init__(self):\n",
        "        self.relations = []\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def add_relation(self, r):\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")"
      ],
      "metadata": {
        "id": "5GRAsz6BZvfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a knowledge base from text\n",
        "def from_small_text_to_kb(text, verbose=False):\n",
        "    kb = KB()\n",
        "\n",
        "    # Tokenizer text\n",
        "    model_inputs = tokenizer(text, max_length=512, padding=True, truncation=True,\n",
        "                            return_tensors='pt')\n",
        "    if verbose:\n",
        "        print(f\"Num tokens: {len(model_inputs['input_ids'][0])}\")\n",
        "\n",
        "    # Generate\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": 216,\n",
        "        \"length_penalty\": 0,\n",
        "        \"num_beams\": 3,\n",
        "        \"num_return_sequences\": 3\n",
        "    }\n",
        "    generated_tokens = model.generate(\n",
        "        **model_inputs,\n",
        "        **gen_kwargs,\n",
        "    )\n",
        "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
        "\n",
        "    # create kb\n",
        "    for sentence_pred in decoded_preds:\n",
        "        relations = extract_relations_from_model_output(sentence_pred)\n",
        "        for r in relations:\n",
        "            kb.add_relation(r)\n",
        "\n",
        "    return kb"
      ],
      "metadata": {
        "id": "7WZ4OhTQZwgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the `from_small_text_to_kb` function\n",
        "\n",
        "text = \"Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August 1769 – 5 \" \\\n",
        "\"May 1821), and later known by his regnal name Napoleon I, was a French military \" \\\n",
        "\"and political leader who rose to prominence during the French Revolution and led \" \\\n",
        "\"several successful campaigns during the Revolutionary Wars. He was the de facto \" \\\n",
        "\"leader of the French Republic as First Consul from 1799 to 1804. As Napoleon I, \" \\\n",
        "\"he was Emperor of the French from 1804 until 1814 and again in 1815. Napoleon's \" \\\n",
        "\"political and cultural legacy has endured, and he has been one of the most \" \\\n",
        "\"celebrated and controversial leaders in world history.\"\n",
        "\n",
        "kb = from_small_text_to_kb(text, verbose=True)\n",
        "kb.print()\n",
        "# Num tokens: 133\n",
        "# Relations:\n",
        "#   {'head': 'Napoleon Bonaparte', 'type': 'date of birth', 'tail': '15 August 1769'}\n",
        "#   {'head': 'Napoleon Bonaparte', 'type': 'date of death', 'tail': '5 May 1821'}\n",
        "#   {'head': 'Napoleon Bonaparte', 'type': 'participant in', 'tail': 'French Revolution'}\n",
        "#   {'head': 'Napoleon Bonaparte', 'type': 'conflict', 'tail': 'Revolutionary Wars'}\n",
        "#   {'head': 'Revolutionary Wars', 'type': 'part of', 'tail': 'French Revolution'}\n",
        "#   {'head': 'French Revolution', 'type': 'participant', 'tail': 'Napoleon Bonaparte'}\n",
        "#   {'head': 'Revolutionary Wars', 'type': 'participant', 'tail': 'Napoleon Bonaparte'}"
      ],
      "metadata": {
        "id": "jNiB2bslZxor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Long Text to KB"
      ],
      "metadata": {
        "id": "ekGnutl3ZzTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add `merge_relations` to KB class\n",
        "class KB():\n",
        "    def __init__(self):\n",
        "        self.relations = []\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def merge_relations(self, r1):\n",
        "        r2 = [r for r in self.relations\n",
        "              if self.are_relations_equal(r1, r)][0]\n",
        "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"]\n",
        "                        if span not in r2[\"meta\"][\"spans\"]]\n",
        "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
        "\n",
        "    def add_relation(self, r):\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "        else:\n",
        "            self.merge_relations(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")"
      ],
      "metadata": {
        "id": "cQ99_R18Z1_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract relations for each span and put them together in a knowledge base\n",
        "def from_text_to_kb(text, span_length=128, verbose=False):\n",
        "    # tokenize whole text\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
        "\n",
        "    # compute span boundaries\n",
        "    num_tokens = len(inputs[\"input_ids\"][0])\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_tokens} tokens\")\n",
        "    num_spans = math.ceil(num_tokens / span_length)\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_spans} spans\")\n",
        "    overlap = math.ceil((num_spans * span_length - num_tokens) /\n",
        "                        max(num_spans - 1, 1))\n",
        "    spans_boundaries = []\n",
        "    start = 0\n",
        "    for i in range(num_spans):\n",
        "        spans_boundaries.append([start + span_length * i,\n",
        "                                 start + span_length * (i + 1)])\n",
        "        start -= overlap\n",
        "    if verbose:\n",
        "        print(f\"Span boundaries are {spans_boundaries}\")\n",
        "\n",
        "    # transform input with spans\n",
        "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
        "                  for boundary in spans_boundaries]\n",
        "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n",
        "                    for boundary in spans_boundaries]\n",
        "    inputs = {\n",
        "        \"input_ids\": torch.stack(tensor_ids),\n",
        "        \"attention_mask\": torch.stack(tensor_masks)\n",
        "    }\n",
        "\n",
        "    # generate relations\n",
        "    num_return_sequences = 3\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": 256,\n",
        "        \"length_penalty\": 0,\n",
        "        \"num_beams\": 3,\n",
        "        \"num_return_sequences\": num_return_sequences\n",
        "    }\n",
        "    generated_tokens = model.generate(\n",
        "        **inputs,\n",
        "        **gen_kwargs,\n",
        "    )\n",
        "\n",
        "    # decode relations\n",
        "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
        "                                           skip_special_tokens=False)\n",
        "\n",
        "    # create kb\n",
        "    kb = KB()\n",
        "    i = 0\n",
        "    for sentence_pred in decoded_preds:\n",
        "        current_span_index = i // num_return_sequences\n",
        "        relations = extract_relations_from_model_output(sentence_pred)\n",
        "        for relation in relations:\n",
        "            relation[\"meta\"] = {\n",
        "                \"spans\": [spans_boundaries[current_span_index]]\n",
        "            }\n",
        "            kb.add_relation(relation)\n",
        "        i += 1\n",
        "\n",
        "    return kb"
      ],
      "metadata": {
        "id": "3ERtBsrPZ4BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August 1769 – 5 May 1821), and later known by his regnal name Napoleon I, was a French military and political leader who rose to prominence during the French Revolution and led several successful campaigns during the Revolutionary Wars. He was the de facto leader of the French Republic as First Consul from 1799 to 1804. As Napoleon I, he was Emperor of the French from 1804 until 1814 and again in 1815. Napoleon's political and cultural legacy has endured, and he has been one of the most celebrated and controversial leaders in world history. Napoleon was born on the island of Corsica not long after its annexation by the Kingdom of France.[5] He supported the French Revolution in 1789 while serving in the French army, and tried to spread its ideals to his native Corsica. He rose rapidly in the Army after he saved the governing French Directory by firing on royalist insurgents. In 1796, he began a military campaign against the Austrians and their Italian allies, scoring decisive victories and becoming a national hero. Two years later, he led a military expedition to Egypt that served as a springboard to political power. He engineered a coup in November 1799 and became First Consul of the Republic. Differences with the British meant that the French faced the War of the Third Coalition by 1805. Napoleon shattered this coalition with victories in the Ulm Campaign, and at the Battle of Austerlitz, which led to the dissolving of the Holy Roman Empire. In 1806, the Fourth Coalition took up arms against him because Prussia became worried about growing French influence on the continent. Napoleon knocked out Prussia at the battles of Jena and Auerstedt, marched the Grande Armée into Eastern Europe, annihilating the Russians in June 1807 at Friedland, and forcing the defeated nations of the Fourth Coalition to accept the Treaties of Tilsit. Two years later, the Austrians challenged the French again during the War of the Fifth Coalition, but Napoleon solidified his grip over Europe after triumphing at the Battle of Wagram. Hoping to extend the Continental System, his embargo against Britain, Napoleon invaded the Iberian Peninsula and declared his brother Joseph King of Spain in 1808. The Spanish and the Portuguese revolted in the Peninsular War, culminating in defeat for Napoleon's marshals. Napoleon launched an invasion of Russia in the summer of 1812. The resulting campaign witnessed the catastrophic retreat of Napoleon's Grande Armée. In 1813, Prussia and Austria joined Russian forces in a Sixth Coalition against France. A chaotic military campaign resulted in a large coalition army defeating Napoleon at the Battle of Leipzig in October 1813. The coalition invaded France and captured Paris, forcing Napoleon to abdicate in April 1814. He was exiled to the island of Elba, between Corsica and Italy. In France, the Bourbons were restored to power. However, Napoleon escaped Elba in February 1815 and took control of France.[6][7] The Allies responded by forming a Seventh Coalition, which defeated Napoleon at the Battle of Waterloo in June 1815. The British exiled him to the remote island of Saint Helena in the Atlantic, where he died in 1821 at the age of 51. Napoleon had an extensive impact on the modern world, bringing liberal reforms to the many countries he conquered, especially the Low Countries, Switzerland, and parts of modern Italy and Germany. He implemented liberal policies in France and Western Europe.\n",
        "\"\"\"\n",
        "\n",
        "kb = from_text_to_kb(text, verbose=True)\n",
        "kb.print()\n",
        "# Input has 726 tokens\n",
        "# Input has 6 spans\n",
        "# Span boundaries are [[0, 128], [119, 247], [238, 366], [357, 485], [476, 604], [595, 723]]\n",
        "# Relations:\n",
        "#   {'head': 'Napoleon Bonaparte', 'type': 'date of birth',\n",
        "#    'tail': '15 August 1769', 'meta': {'spans': [[0, 128]]}}\n",
        "#   ...\n",
        "#   {'head': 'Napoleon', 'type': 'place of birth',\n",
        "#    'tail': 'Corsica', 'meta': {'spans': [[119, 247]]}}\n",
        "#   ...\n",
        "#   {'head': 'Fourth Coalition', 'type': 'start time',\n",
        "#    'tail': '1806', 'meta': {'spans': [[238, 366]]}}\n",
        "#   ..."
      ],
      "metadata": {
        "id": "9g4mZxa_Z5G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter and Normalize Entities with Wikipedia\n",
        "- remove all entities that doesn't have a page on Wikipedia\n",
        "- merge entities if they have the same wikipedia page"
      ],
      "metadata": {
        "id": "qzyf_2jIZ7I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter and normalize entities before adding them to the KB\n",
        "class KB():\n",
        "    def __init__(self):\n",
        "        self.entities = {}\n",
        "        self.relations = []\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def merge_relations(self, r1):\n",
        "        r2 = [r for r in self.relations\n",
        "              if self.are_relations_equal(r1, r)][0]\n",
        "        spans_to_add = [span for span in r1[\"meta\"][\"spans\"]\n",
        "                        if span not in r2[\"meta\"][\"spans\"]]\n",
        "        r2[\"meta\"][\"spans\"] += spans_to_add\n",
        "\n",
        "    def get_wikipedia_data(self, candidate_entity):\n",
        "        try:\n",
        "            page = wikipedia.page(candidate_entity, auto_suggest=False)\n",
        "            entity_data = {\n",
        "                \"title\": page.title,\n",
        "                \"url\": page.url,\n",
        "                \"summary\": page.summary\n",
        "            }\n",
        "            return entity_data\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def add_entity(self, e):\n",
        "        self.entities[e[\"title\"]] = {k:v for k,v in e.items() if k != \"title\"}\n",
        "\n",
        "    def add_relation(self, r):\n",
        "        # check on wikipedia\n",
        "        candidate_entities = [r[\"head\"], r[\"tail\"]]\n",
        "        entities = [self.get_wikipedia_data(ent) for ent in candidate_entities]\n",
        "\n",
        "        # if one entity does not exist, stop\n",
        "        if any(ent is None for ent in entities):\n",
        "            return\n",
        "\n",
        "        # manage new entities\n",
        "        for e in entities:\n",
        "            self.add_entity(e)\n",
        "\n",
        "        # rename relation entities with their wikipedia titles\n",
        "        r[\"head\"] = entities[0][\"title\"]\n",
        "        r[\"tail\"] = entities[1][\"title\"]\n",
        "\n",
        "        # manage new relation\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "        else:\n",
        "            self.merge_relations(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Entities:\")\n",
        "        for e in self.entities.items():\n",
        "            print(f\"  {e}\")\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")"
      ],
      "metadata": {
        "id": "OWJNDhUlZ8YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August 1769 – 5 May 1821), and later known by his regnal name Napoleon I, was a French military and political leader who rose to prominence during the French Revolution and led several successful campaigns during the Revolutionary Wars. He was the de facto leader of the French Republic as First Consul from 1799 to 1804. As Napoleon I, he was Emperor of the French from 1804 until 1814 and again in 1815. Napoleon's political and cultural legacy has endured, and he has been one of the most celebrated and controversial leaders in world history. Napoleon was born on the island of Corsica not long after its annexation by the Kingdom of France.[5] He supported the French Revolution in 1789 while serving in the French army, and tried to spread its ideals to his native Corsica. He rose rapidly in the Army after he saved the governing French Directory by firing on royalist insurgents. In 1796, he began a military campaign against the Austrians and their Italian allies, scoring decisive victories and becoming a national hero. Two years later, he led a military expedition to Egypt that served as a springboard to political power. He engineered a coup in November 1799 and became First Consul of the Republic. Differences with the British meant that the French faced the War of the Third Coalition by 1805. Napoleon shattered this coalition with victories in the Ulm Campaign, and at the Battle of Austerlitz, which led to the dissolving of the Holy Roman Empire. In 1806, the Fourth Coalition took up arms against him because Prussia became worried about growing French influence on the continent. Napoleon knocked out Prussia at the battles of Jena and Auerstedt, marched the Grande Armée into Eastern Europe, annihilating the Russians in June 1807 at Friedland, and forcing the defeated nations of the Fourth Coalition to accept the Treaties of Tilsit. Two years later, the Austrians challenged the French again during the War of the Fifth Coalition, but Napoleon solidified his grip over Europe after triumphing at the Battle of Wagram. Hoping to extend the Continental System, his embargo against Britain, Napoleon invaded the Iberian Peninsula and declared his brother Joseph King of Spain in 1808. The Spanish and the Portuguese revolted in the Peninsular War, culminating in defeat for Napoleon's marshals. Napoleon launched an invasion of Russia in the summer of 1812. The resulting campaign witnessed the catastrophic retreat of Napoleon's Grande Armée. In 1813, Prussia and Austria joined Russian forces in a Sixth Coalition against France. A chaotic military campaign resulted in a large coalition army defeating Napoleon at the Battle of Leipzig in October 1813. The coalition invaded France and captured Paris, forcing Napoleon to abdicate in April 1814. He was exiled to the island of Elba, between Corsica and Italy. In France, the Bourbons were restored to power. However, Napoleon escaped Elba in February 1815 and took control of France.[6][7] The Allies responded by forming a Seventh Coalition, which defeated Napoleon at the Battle of Waterloo in June 1815. The British exiled him to the remote island of Saint Helena in the Atlantic, where he died in 1821 at the age of 51. Napoleon had an extensive impact on the modern world, bringing liberal reforms to the many countries he conquered, especially the Low Countries, Switzerland, and parts of modern Italy and Germany. He implemented liberal policies in France and Western Europe.\n",
        "\"\"\"\n",
        "\n",
        "kb = from_text_to_kb(text)\n",
        "kb.print()\n",
        "# Entities:\n",
        "#  ('Napoleon', {'url': 'https://en.wikipedia.org/wiki/Napoleon',\n",
        "#   'summary': \"Napoleon Bonaparte (born Napoleone di Buonaparte; 15 August ...\"})\n",
        "#  ('French Revolution', {'url': 'https://en.wikipedia.org/wiki/French_Revolution',\n",
        "#   'summary': 'The French Revolution (French: Révolution française...\"})\n",
        "#  ...\n",
        "# Relations:\n",
        "#  {'head': 'Napoleon', 'type': 'participant in', 'tail': 'French Revolution',\n",
        "#   'meta': {'spans': [[0, 128], [119, 247]]}}\n",
        "#  {'head': 'French Revolution', 'type': 'participant', 'tail': 'Napoleon',\n",
        "#   'meta': {'spans': [[0, 128]]}}\n",
        "#  ..."
      ],
      "metadata": {
        "id": "LCvYWZCjZ9zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract KB from Web Article"
      ],
      "metadata": {
        "id": "9pDptrt1aAik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep track of where relations have been extracted\n",
        "class KB():\n",
        "    def __init__(self):\n",
        "        self.entities = {} # { entity_title: {...} }\n",
        "        self.relations = [] # [ head: entity_title, type: ..., tail: entity_title,\n",
        "          # meta: { article_url: { spans: [...] } } ]\n",
        "        self.sources = {} # { article_url: {...} }\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def merge_relations(self, r2):\n",
        "        r1 = [r for r in self.relations\n",
        "              if self.are_relations_equal(r2, r)][0]\n",
        "\n",
        "        # if different article\n",
        "        article_url = list(r2[\"meta\"].keys())[0]\n",
        "        if article_url not in r1[\"meta\"]:\n",
        "            r1[\"meta\"][article_url] = r2[\"meta\"][article_url]\n",
        "\n",
        "        # if existing article\n",
        "        else:\n",
        "            spans_to_add = [span for span in r2[\"meta\"][article_url][\"spans\"]\n",
        "                            if span not in r1[\"meta\"][article_url][\"spans\"]]\n",
        "            r1[\"meta\"][article_url][\"spans\"] += spans_to_add\n",
        "\n",
        "    def get_wikipedia_data(self, candidate_entity):\n",
        "        try:\n",
        "            page = wikipedia.page(candidate_entity, auto_suggest=False)\n",
        "            entity_data = {\n",
        "                \"title\": page.title,\n",
        "                \"url\": page.url,\n",
        "                \"summary\": page.summary\n",
        "            }\n",
        "            return entity_data\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def add_entity(self, e):\n",
        "        self.entities[e[\"title\"]] = {k:v for k,v in e.items() if k != \"title\"}\n",
        "\n",
        "    def add_relation(self, r, article_title, article_publish_date):\n",
        "        # check on wikipedia\n",
        "        candidate_entities = [r[\"head\"], r[\"tail\"]]\n",
        "        entities = [self.get_wikipedia_data(ent) for ent in candidate_entities]\n",
        "\n",
        "        # if one entity does not exist, stop\n",
        "        if any(ent is None for ent in entities):\n",
        "            return\n",
        "\n",
        "        # manage new entities\n",
        "        for e in entities:\n",
        "            self.add_entity(e)\n",
        "\n",
        "        # rename relation entities with their wikipedia titles\n",
        "        r[\"head\"] = entities[0][\"title\"]\n",
        "        r[\"tail\"] = entities[1][\"title\"]\n",
        "\n",
        "        # add source if not in kb\n",
        "        article_url = list(r[\"meta\"].keys())[0]\n",
        "        if article_url not in self.sources:\n",
        "            self.sources[article_url] = {\n",
        "                \"article_title\": article_title,\n",
        "                \"article_publish_date\": article_publish_date\n",
        "            }\n",
        "\n",
        "        # manage new relation\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "        else:\n",
        "            self.merge_relations(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Entities:\")\n",
        "        for e in self.entities.items():\n",
        "            print(f\"  {e}\")\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")\n",
        "        print(\"Sources:\")\n",
        "        for s in self.sources.items():\n",
        "            print(f\"  {s}\")"
      ],
      "metadata": {
        "id": "2DGUEdh0aF76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract text from url, extract relations and populate the KB\n",
        "def from_text_to_kb(text, article_url, span_length=128, article_title=None,\n",
        "                    article_publish_date=None, verbose=False):\n",
        "    # tokenize whole text\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
        "\n",
        "    # compute span boundaries\n",
        "    num_tokens = len(inputs[\"input_ids\"][0])\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_tokens} tokens\")\n",
        "    num_spans = math.ceil(num_tokens / span_length)\n",
        "    if verbose:\n",
        "        print(f\"Input has {num_spans} spans\")\n",
        "    overlap = math.ceil((num_spans * span_length - num_tokens) /\n",
        "                        max(num_spans - 1, 1))\n",
        "    spans_boundaries = []\n",
        "    start = 0\n",
        "    for i in range(num_spans):\n",
        "        spans_boundaries.append([start + span_length * i,\n",
        "                                 start + span_length * (i + 1)])\n",
        "        start -= overlap\n",
        "    if verbose:\n",
        "        print(f\"Span boundaries are {spans_boundaries}\")\n",
        "\n",
        "    # transform input with spans\n",
        "    tensor_ids = [inputs[\"input_ids\"][0][boundary[0]:boundary[1]]\n",
        "                  for boundary in spans_boundaries]\n",
        "    tensor_masks = [inputs[\"attention_mask\"][0][boundary[0]:boundary[1]]\n",
        "                    for boundary in spans_boundaries]\n",
        "    inputs = {\n",
        "        \"input_ids\": torch.stack(tensor_ids),\n",
        "        \"attention_mask\": torch.stack(tensor_masks)\n",
        "    }\n",
        "\n",
        "    # generate relations\n",
        "    num_return_sequences = 3\n",
        "    gen_kwargs = {\n",
        "        \"max_length\": 256,\n",
        "        \"length_penalty\": 0,\n",
        "        \"num_beams\": 3,\n",
        "        \"num_return_sequences\": num_return_sequences\n",
        "    }\n",
        "    generated_tokens = model.generate(\n",
        "        **inputs,\n",
        "        **gen_kwargs,\n",
        "    )\n",
        "\n",
        "    # decode relations\n",
        "    decoded_preds = tokenizer.batch_decode(generated_tokens,\n",
        "                                           skip_special_tokens=False)\n",
        "\n",
        "    # create kb\n",
        "    kb = KB()\n",
        "    i = 0\n",
        "    for sentence_pred in decoded_preds:\n",
        "        current_span_index = i // num_return_sequences\n",
        "        relations = extract_relations_from_model_output(sentence_pred)\n",
        "        for relation in relations:\n",
        "            relation[\"meta\"] = {\n",
        "                article_url: {\n",
        "                    \"spans\": [spans_boundaries[current_span_index]]\n",
        "                }\n",
        "            }\n",
        "            kb.add_relation(relation, article_title, article_publish_date)\n",
        "        i += 1\n",
        "\n",
        "    return kb"
      ],
      "metadata": {
        "id": "T5yyMD_jaCmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parse an article with newspaper3k\n",
        "def get_article(url):\n",
        "    article = Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    return article\n",
        "\n",
        "# extract the article from the url (along with metadata), extract relations and populate a KB\n",
        "def from_url_to_kb(url):\n",
        "    article = get_article(url)\n",
        "    config = {\n",
        "        \"article_title\": article.title,\n",
        "        \"article_publish_date\": article.publish_date\n",
        "    }\n",
        "    kb = from_text_to_kb(article.text, article.url, **config)\n",
        "    return kb"
      ],
      "metadata": {
        "id": "TBA2iWDbaHQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the `from_url_to_kb` function\n",
        "url = \"https://finance.yahoo.com/news/microstrategy-bitcoin-millions-142143795.html\"\n",
        "kb = from_url_to_kb(url)\n",
        "kb.print()\n",
        "# Entities:\n",
        "#   ('MicroStrategy', {'url': 'https://en.wikipedia.org/wiki/MicroStrategy',\n",
        "#     'summary': \"MicroStrategy Incorporated is an American company that ...\"})\n",
        "#   ('Michael J. Saylor', {'url': 'https://en.wikipedia.org/wiki/Michael_J._Saylor',\n",
        "#     'summary': 'Michael J. Saylor (born February 4, 1965) is an American ...\"})\n",
        "#   ...\n",
        "# Relations:\n",
        "#   {'head': 'MicroStrategy', 'type': 'founded by', 'tail': 'Michael J. Saylor',\n",
        "#    'meta': {'https://finance.yahoo.com/news/microstrategy-bitcoin-millions-142143795.html':\n",
        "#      {'spans': [[0, 128]]}}}\n",
        "#   {'head': 'Michael J. Saylor', 'type': 'employer', 'tail': 'MicroStrategy',\n",
        "#    'meta': {'https://finance.yahoo.com/news/microstrategy-bitcoin-millions-142143795.html':\n",
        "#      {'spans': [[0, 128]]}}}\n",
        "#   ...\n",
        "# Sources:\n",
        "#   ('https://finance.yahoo.com/news/microstrategy-bitcoin-millions-142143795.html',\n",
        "#     {'article_title': \"Microstrategy chief: 'Bitcoin is going to go into the millions'\",\n",
        "#      'article_publish_date': None})"
      ],
      "metadata": {
        "id": "4swu4FU0aIZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google News: Extract KB from Multiple Articles"
      ],
      "metadata": {
        "id": "iHjCXDJHaKIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep track of where relations have been extracted\n",
        "class KB():\n",
        "    def __init__(self):\n",
        "        self.entities = {} # { entity_title: {...} }\n",
        "        self.relations = [] # [ head: entity_title, type: ..., tail: entity_title,\n",
        "          # meta: { article_url: { spans: [...] } } ]\n",
        "        self.sources = {} # { article_url: {...} }\n",
        "\n",
        "    def merge_with_kb(self, kb2):\n",
        "        for r in kb2.relations:\n",
        "            article_url = list(r[\"meta\"].keys())[0]\n",
        "            source_data = kb2.sources[article_url]\n",
        "            self.add_relation(r, source_data[\"article_title\"],\n",
        "                              source_data[\"article_publish_date\"])\n",
        "\n",
        "    def are_relations_equal(self, r1, r2):\n",
        "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
        "\n",
        "    def exists_relation(self, r1):\n",
        "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
        "\n",
        "    def merge_relations(self, r2):\n",
        "        r1 = [r for r in self.relations\n",
        "              if self.are_relations_equal(r2, r)][0]\n",
        "\n",
        "        # if different article\n",
        "        article_url = list(r2[\"meta\"].keys())[0]\n",
        "        if article_url not in r1[\"meta\"]:\n",
        "            r1[\"meta\"][article_url] = r2[\"meta\"][article_url]\n",
        "\n",
        "        # if existing article\n",
        "        else:\n",
        "            spans_to_add = [span for span in r2[\"meta\"][article_url][\"spans\"]\n",
        "                            if span not in r1[\"meta\"][article_url][\"spans\"]]\n",
        "            r1[\"meta\"][article_url][\"spans\"] += spans_to_add\n",
        "\n",
        "    def get_wikipedia_data(self, candidate_entity):\n",
        "        try:\n",
        "            page = wikipedia.page(candidate_entity, auto_suggest=False)\n",
        "            entity_data = {\n",
        "                \"title\": page.title,\n",
        "                \"url\": page.url,\n",
        "                \"summary\": page.summary\n",
        "            }\n",
        "            return entity_data\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def add_entity(self, e):\n",
        "        self.entities[e[\"title\"]] = {k:v for k,v in e.items() if k != \"title\"}\n",
        "\n",
        "    def add_relation(self, r, article_title, article_publish_date):\n",
        "        # check on wikipedia\n",
        "        candidate_entities = [r[\"head\"], r[\"tail\"]]\n",
        "        entities = [self.get_wikipedia_data(ent) for ent in candidate_entities]\n",
        "\n",
        "        # if one entity does not exist, stop\n",
        "        if any(ent is None for ent in entities):\n",
        "            return\n",
        "\n",
        "        # manage new entities\n",
        "        for e in entities:\n",
        "            self.add_entity(e)\n",
        "\n",
        "        # rename relation entities with their wikipedia titles\n",
        "        r[\"head\"] = entities[0][\"title\"]\n",
        "        r[\"tail\"] = entities[1][\"title\"]\n",
        "\n",
        "        # add source if not in kb\n",
        "        article_url = list(r[\"meta\"].keys())[0]\n",
        "        if article_url not in self.sources:\n",
        "            self.sources[article_url] = {\n",
        "                \"article_title\": article_title,\n",
        "                \"article_publish_date\": article_publish_date\n",
        "            }\n",
        "\n",
        "        # manage new relation\n",
        "        if not self.exists_relation(r):\n",
        "            self.relations.append(r)\n",
        "        else:\n",
        "            self.merge_relations(r)\n",
        "\n",
        "    def print(self):\n",
        "        print(\"Entities:\")\n",
        "        for e in self.entities.items():\n",
        "            print(f\"  {e}\")\n",
        "        print(\"Relations:\")\n",
        "        for r in self.relations:\n",
        "            print(f\"  {r}\")\n",
        "        print(\"Sources:\")\n",
        "        for s in self.sources.items():\n",
        "            print(f\"  {s}\")"
      ],
      "metadata": {
        "id": "haEABhI5IeQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get news links from google news\n",
        "def get_news_links(query, lang=\"en\", region=\"US\", pages=1, max_links=100000):\n",
        "    googlenews = GoogleNews(lang=lang, region=region)\n",
        "    googlenews.search(query)\n",
        "    all_urls = []\n",
        "    for page in range(pages):\n",
        "        googlenews.get_page(page)\n",
        "        all_urls += googlenews.get_links()\n",
        "    return list(set(all_urls))[:max_links]\n",
        "\n",
        "# build a KB from multiple news links\n",
        "def from_urls_to_kb(urls, verbose=False):\n",
        "    kb = KB()\n",
        "    if verbose:\n",
        "        print(f\"{len(urls)} links to visit\")\n",
        "    for url in urls:\n",
        "        if verbose:\n",
        "            print(f\"Visiting {url}...\")\n",
        "        try:\n",
        "            kb_url = from_url_to_kb(url)\n",
        "            kb.merge_with_kb(kb_url)\n",
        "        except ArticleException:\n",
        "            if verbose:\n",
        "                print(f\"  Couldn't download article at url {url}\")\n",
        "    return kb"
      ],
      "metadata": {
        "id": "daunNBAvaL7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the `from_urls_to_kb` function\n",
        "news_links = get_news_links(\"Google\", pages=1, max_links=3)\n",
        "kb = from_urls_to_kb(news_links, verbose=True)\n",
        "kb.print()\n",
        "# 3 links to visit\n",
        "# Visiting https://www.hindustantimes.com/india-news/google-doodle-celebrates-india-s-gama-pehlwan-the-undefeated-wrestling-champion-101653180853982.html...\n",
        "# Visiting https://tech.hindustantimes.com/tech/news/google-doodle-today-celebrates-gama-pehlwan-s-144th-birth-anniversary-know-who-he-is-71653191916538.html...\n",
        "# Visiting https://www.moneycontrol.com/news/trends/current-affairs-trends/google-doodle-celebrates-gama-pehlwan-the-amritsar-born-wrestling-champ-who-inspired-bruce-lee-8552171.html...\n",
        "# Entities:\n",
        "#   ('Google', {'url': 'https://en.wikipedia.org/wiki/Google',\n",
        "#     'summary': 'Google LLC is an American ...'})\n",
        "#   ...\n",
        "# Relations:\n",
        "#   {'head': 'Google', 'type': 'owner of', 'tail': 'Google Doodle',\n",
        "#     'meta': {'https://tech.hindustantimes.com/tech/news/google-doodle-today-celebrates-gama-pehlwan-s-144th-birth-anniversary-know-who-he-is-71653191916538.html':\n",
        "#       {'spans': [[0, 128]]}}}\n",
        "#   ...\n",
        "# Sources:\n",
        "#   ('https://www.hindustantimes.com/india-news/google-doodle-celebrates-india-s-gama-pehlwan-the-undefeated-wrestling-champion-101653180853982.html',\n",
        "#     {'article_title': \"Google Doodle celebrates India's Gama Pehlwan, the undefeated wrestling champion\",\n",
        "#     'article_publish_date': datetime.datetime(2022, 5, 22, 6, 59, 56, tzinfo=tzoffset(None, 19800))})\n",
        "#   ('https://tech.hindustantimes.com/tech/news/google-doodle-today-celebrates-gama-pehlwan-s-144th-birth-anniversary-know-who-he-is-71653191916538.html',\n",
        "#     {'article_title': \"Google Doodle today celebrates Gama Pehlwan's 144th birth anniversary; know who he is\",\n",
        "#     'article_publish_date': datetime.datetime(2022, 5, 22, 9, 32, 38, tzinfo=tzoffset(None, 19800))})\n",
        "#   ('https://www.moneycontrol.com/news/trends/current-affairs-trends/google-doodle-celebrates-gama-pehlwan-the-amritsar-born-wrestling-champ-who-inspired-bruce-lee-8552171.html',\n",
        "#     {'article_title': 'Google Doodle celebrates Gama Pehlwan, the Amritsar-born wrestling champ who inspired Bruce Lee',\n",
        "#     'article_publish_date': None})"
      ],
      "metadata": {
        "id": "jPWaENfWaOTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize KB"
      ],
      "metadata": {
        "id": "zj6Bp8IaaSPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from KB to HTML visualization\n",
        "def save_network_html(kb, filename=\"network.html\"):\n",
        "    # create network\n",
        "    net = Network(directed=True, width=\"auto\", height=\"700px\", bgcolor=\"#eeeeee\")\n",
        "\n",
        "    # nodes\n",
        "    color_entity = \"#00FF00\"\n",
        "    for e in kb.entities:\n",
        "        net.add_node(e, shape=\"circle\", color=color_entity)\n",
        "\n",
        "    # edges\n",
        "    for r in kb.relations:\n",
        "        net.add_edge(r[\"head\"], r[\"tail\"],\n",
        "                    title=r[\"type\"], label=r[\"type\"])\n",
        "\n",
        "    # save network\n",
        "    net.repulsion(\n",
        "        node_distance=200,\n",
        "        central_gravity=0.2,\n",
        "        spring_length=200,\n",
        "        spring_strength=0.05,\n",
        "        damping=0.09\n",
        "    )\n",
        "    net.set_edge_smooth('dynamic')\n",
        "    net.show(filename)"
      ],
      "metadata": {
        "id": "xA90jXi2aS3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract KB from news about Google and visualize it\n",
        "news_links = get_news_links(\"Google\", pages=5, max_links=20)\n",
        "kb = from_urls_to_kb(news_links, verbose=True)\n",
        "filename = \"network_3_google.html\"\n",
        "save_network_html(kb, filename=filename)"
      ],
      "metadata": {
        "id": "JjWtn8CDaU6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Exercises"
      ],
      "metadata": {
        "id": "YmWMsDSZHKW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Currently most \"dates\" extracted by REBEL are filtered out in the entity linking step. Modify the pipeline to keep them in the KB."
      ],
      "metadata": {
        "id": "t3sfFJyyHLuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE CODE HERE"
      ],
      "metadata": {
        "id": "ko1o0QjzHLVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Modify the relation extraction pipeline to use sentence boundaries as span boundaries."
      ],
      "metadata": {
        "id": "FhqAH_ECKT09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE CODE HERE"
      ],
      "metadata": {
        "id": "gRQspB5nKlfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Test other NER and Relation Classification models, such as OpenNRE."
      ],
      "metadata": {
        "id": "f87MhTIHKcJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE CODE HERE"
      ],
      "metadata": {
        "id": "LOeKytaeKlwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise: Add a function that computes a quality metric for each relation, taking into account the relation sources."
      ],
      "metadata": {
        "id": "SxgGv5VQKgHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE CODE HERE"
      ],
      "metadata": {
        "id": "9kzduG8lKhbc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}